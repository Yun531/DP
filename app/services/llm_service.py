import google.generativeai as genai
genai.configure(api_key="AIzaSyAY3DtZzT-9yIJtoIwMP3_iFhGmNN6TlY0")
from typing import List
from app.dtos.crawled_paper_dto import CrawledPaper
from app.dtos.keyword_summary_dto import KeywordSummaryResult
from app.dtos.summarized_paper_dto import SummarizedPaper
import pika
import json


def extract_keywords(text: str) -> KeywordSummaryResult:
    """
    íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¡œë¶€í„° í‚¤ì›Œë“œì™€ ìš”ì•½ì„ ì¶”ì¶œ (Gemini API í™œìš©)
    """
    meeting_prompt = f"""
    The following is a meeting transcript from a research lab.
    Please extract exactly 5 core research keywords from the transcript.
    Each keyword must be a single English word (no phrases).
    Do not include any symbols (e.g., asterisks, parentheses, semicolons).
    Return only the 5 words as a plain list without any formatting or explanations.

    [Meeting Transcript]
    ---
    {text}
    ---
    """
    model = genai.GenerativeModel("gemini-1.5-flash")
    response = model.generate_content(meeting_prompt)
    # Gemini ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ˆ: ['í‚¤ì›Œë“œ1', 'í‚¤ì›Œë“œ2', ...])
    keywords = []
    for line in response.text.strip().splitlines():
        kw = line.strip("-â€¢* ")
        if kw:
            keywords.append(kw)
    keywords = keywords[:5]

    # #ë°œí‘œìš© í‚¤ì›Œë“œ
    # keywords = ["Big Data", "Lamda Architecture", "Hadoop"]

    summary_prompt = f"""
    ë‹¤ìŒì€ í•œ ì—°êµ¬ì‹¤ì˜ íšŒì˜ë¡ì…ë‹ˆë‹¤.
    ì´ íšŒì˜ë¡ì˜ ì£¼ìš” ë…¼ì˜ ë‚´ìš©ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

    [íšŒì˜ë¡ ì…ë ¥]
    ---
    {text}
    ---
    """
    summary_response = model.generate_content(summary_prompt)
    summary = summary_response.text.strip()

    return KeywordSummaryResult(
        summary=summary,
        keywords=keywords
    )

def summarize_papers(papers: List[CrawledPaper]) -> List[SummarizedPaper]:
    """
    í¬ë¡¤ë§ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ìš”ì•½ì„ ì¶”ê°€í•œ SummarizedPaper ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (Gemini API í™œìš©)
    """
    results = []
    model = genai.GenerativeModel("gemini-1.5-flash")
    for paper in papers:
        text = paper.text_content
        print(f"[LLM] {paper.title} | í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text) if text else 0}")
        
        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš°ë§Œ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
        if not text or len(text) < 100:  # ìµœì†Œ 100ì ì´ìƒì€ ë˜ì–´ì•¼ í•¨
            print(f"[LLM] {paper.title} | í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ")
            summary = "í¬ë¡¤ë§ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤. urlì— ì§ì ‘ ì ‘ì†í•´ì„œ ë…¼ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
            # if len(text) > 15000:
            #     print(f"[LLM] {paper.title} | í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ ì• 15000ìë§Œ ì‚¬ìš©")
            #     text = text[:15000]
            
            paper_prompt = f"""
            ë‹¤ìŒ ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ 10~12ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.  
            ë…¼ë¬¸ì´ í•´ê²°í•˜ê³ ì í•œ ë¬¸ì œ, ì œì•ˆí•œ ë°©ë²•, ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì„œìˆ í•´ ì£¼ì„¸ìš”.

            [ë…¼ë¬¸ ì´ˆë¡]
            ---
            {text}
            ---
            """
            try:
                print(f"[LLM] {paper.title} | Gemini API í˜¸ì¶œ ì‹œì‘")
                response = model.generate_content(paper_prompt)
                summary = response.text.strip()
                print(f"[LLM] {paper.title} | Gemini API í˜¸ì¶œ ì„±ê³µ")
            except Exception as e:
                print(f"[LLM] {paper.title} | ìš”ì•½ ì¤‘ ì˜ˆì™¸: {e}")
                summary = "ìš”ì•½ ë¶ˆê°€: LLM ì˜ˆì™¸ ë°œìƒ"
        
        results.append(SummarizedPaper(
            paper_id=paper.paper_id,
            title=paper.title,
            thesis_url=paper.thesis_url,
            text_content=paper.text_content,
            summary=summary
        ))
    return results


class LLMService:
    def __init__(self):
        # RabbitMQ ì—°ê²°
        credentials = pika.PlainCredentials('guest', 'guest')
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host='localhost',  # ë„ì»¤ ì‚¬ìš© ì‹œ: rabbitmq
                credentials=credentials
            )
        )
        self.channel = self.connection.channel()
        self.channel.queue_declare(queue='paper_processing')
        self.start_consumer()

    def start_consumer(self):
        def consumer_thread():
            def callback(ch, method, properties, body):
                try:
                    papers_data = json.loads(body)
                    papers = [Paper.from_dict(p) for p in papers_data]

                    print(f"ğŸ“¦ ë°›ì€ ë©”ì‹œì§€ - ì´ {len(papers)}ê°œ ë…¼ë¬¸")
                    for paper in papers:
                        print(f"- ë…¼ë¬¸ ID: {paper.paper_id}")
                        print(f"  ì œëª©: {paper.title}")
                        print(f"  URL: {paper.thesis_url}")
                        print(f"  ë‚´ìš© ê¸¸ì´: {len(paper.text_content)}ì")
                        print("--------------------------------------------------")

                except Exception as e:
                    print(f"[ERROR] ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                finally:
                    ch.basic_ack(delivery_tag=method.delivery_tag)

            self.channel.basic_qos(prefetch_count=1)
            self.channel.basic_consume(
                queue='paper_processing',
                on_message_callback=callback
            )
            print('[RabbitMQ] ë…¼ë¬¸ ë©”ì‹œì§€ ì†Œë¹„ ì‹œì‘...')
            self.channel.start_consuming()

        self.consumer_thread = threading.Thread(target=consumer_thread, daemon=True)
        self.consumer_thread.start()
